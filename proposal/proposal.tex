\documentclass{article}
\usepackage{natbib}
\usepackage{color}
\usepackage[pdftex, pdfborderstyle={/S/U/W 0}]{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\author{Andrew Cave}
\title{Dependent type theory for contextual reasoning}

\definecolor{light-gray}{gray}{0.5}
\newcommand{\LONGVERSION}[1]{{\color{light-gray}#1}}

\begin{document}
\maketitle

\section{Introduction}

%(todo: look at other examples of thesis statements)

Increasingly, there is a desire to write computer checked proofs for
research in programming languages and logic
\citep{POPLMark}. Results in programming languages appear to be prime
candidates for computer checked proofs. For one, these proofs typically take the
form of a proof by induction with many cases, and formalizing inductive
reasoning is by now quite well understood. Moreover, the abundance of cases means that such proofs can be
tedious and error-prone to write and to verify by hand. Fortunately, it is now commonplace for proof
assistants to not only check that all cases have been covered, but
even to automatically generate the list of cases for the human prover
to consider, so that constructing a proof becomes an interactive effort.

However, formalizing such proofs can still be tedious for at least one reason,
namely giving a formal treatment of variable binding and
substitution. \cite{Altenkirch93} writes (about
formalizing a proof of normalization for System F):

\begin{quote}
When doing the formalization, I discovered that the core part of the
proof (here proving the lemmas about CR) is fairly straightforward and
only requires a good understanding of the paper version. However, in
completing the proof I observed that in certain places I had to invest
much more work than expected, e.g. proving lemmas about substitution
and weakening.
\end{quote}

This issue has spawned a large body of work aiming to relieve this
particular burden.

The logical framework LF \citep{Harper93jacm} has proven to be well-suited for representing
programming language syntax, logics and hypothetical
judgments. However, it has been less clear how to formulate induction
over LF representations in a way that is directly comparable to
induction over a first-order representation like de Bruijn indices or
names. (? is this fair? cite?)

However, the most effective approaches to this problem have
come at a fairly steep price: fairly weak logics. (elaborate)


There are a handful of approaches to logics and theories suitable for
machine checked proofs. Higher order logic, set theory, and dependent
type theory are the main alternatives which are rich enough to serve
as a foundation for modern mathematics. Among these, dependent type theory
\citep{Martin-Loef73a} boasts the advantage that it comes equipped with a direct
connection to computer programming. This means that it provides a rich
environment which at the same time supports both proofs and
programs. By constructing a proof in dependent type theory, one has
implicitly also constructed a corresponding algorithm which can be
directly executed. This is very valuable, because it
enables the development of theory to proceed hand in hand
with implementation. Moreover, (intensional) dependent type theory offers a
principled approach to incorporating automated
support for a decidable equational theory, which is of primary concern
for the proposed work.
NuPRL \citep{NuPRL} Agda \citep{Norell:phd07} Coq
\citep{bertot/casteran:2004}

Thesis statement: Building a logical framework into dependent type
theory is possible and makes mechanization of state-of-the-art programming
language metatheory more effective. Moreover: it shows promise for a rich programming
environment in which to implement programming languages and logics, which allows
implementation to be carried out jointly with a ``sliding-scale'' of verification.


\section{Background}
Sketch well-scoped representation in Agda and substitution
principles. Illustrate the point that the main bottleneck for
mechanization are the equations which arise (e.g. church rosser proof?
similar experiments as far as proving normalization for MLTT with a universe)

\begin{itemize}
\item Standard issues in mechanizing metatheory: first order
  representations require defining weakening, substitution, and proving
  equations pertaining to (compositions of) weakening and
  substitution.
\item Higher-order abstract syntax solves some of these issues, but it
  is not so clear how to combine with rich type theories and logics
\item Contrast dependent type theory with indexed types (e.g. Beluga) and first-order
logic (e.g. Abella). 

\item Primary examples are logical relations, like Coquand's type
directed conversion (and our ITP submission), soundness/completeness of NbE
(cite e.g. Abel for recent work, Dybjer for original?),
step-indexed logical relations for reasoning about effects

\item clarify distinction with Hybrid: I'm proposing to use language design
techniques to give better support (definitional equalities for
simultaneous substitutions).

\item design space: systems with support for binding and substitution vs
systems with rich abstraction mechanisms and logical strength

Definition of substitution with names:

\begin{eqnarray*}
[N/x](x) & = & N \\
 \lbrack N/x](y) & = & y \quad \text{if $x \neq y$} \\
 \lbrack N/x](M_1 M_2) & = & ([N/x]M_1) ([N/x]M_2) \\
 \lbrack N/x](\lambda y. M) & = & \lambda y. [N/x]M \quad
 \text{choosing $y \not\in fv(N)$ and
  $y \neq x$}
\end{eqnarray*}

%``A domain-specific dependent type theory''

% though actually this isn't the worst of it, the worst of it is
% establishing necessary equational properties of substitution and weakening
% (freshness in the nominal world, shifts in the de Bruijn world) (cite
% Altenkirch) and deducing equations from the resulting equational
% theory.

%classic: $[P/y]([N/x]M) = [([P/y]N)/x] ([P/y]M)$ provided $x\neq y$
%(check this: Barendregt?)

%distinction between techniques for supporting ``names'', weakening, freshness (nominal) and ``substitution''.

%dependent type theory allows effective programming and proving
\end{itemize}

Proofs in programming language metatheory have lots of cases (which
can often be generated/developed interactively), which is why they're
a good candidate for formalization.

Existing systems targetting support for programming language
  metatheory handle well proofs which require modest logical
  strength, such as proofs of confluence and type safety. However,
  increasingly the programming language community is interested in
  topics such as normalization, parametricity \citep{Reynolds,morerecent?}, decidability of
  typechecking \citep{Coquand?}, (step-indexed) logical relations for contextual
  equivalence \citep{Dreyer11,others}, soundness and completenes of
  NbE \citep{Dybjer00,Abel07}, all of which require
  richer logics to express. Sometimes also simple requirements like
  concatenation of contexts -- can't directly be expressed in Twelf
  (can in Beluga), can often be worked around, but why not directly? 
  By giving a more seemless integration of a logical framework
  into dependent type theory (i.e. no separation between levels) this
  can be accomplished.

Also forgetful maps on contexts (v.s. representation using relations
and proving totality, etc)

Also to properly justify logical relations arguments and use existing
understanding of termination. (We ``cheat'' in Beluga to do logical relations)

(Can I claim that the PL community is one of the biggest users of
proof assistants, hence it makes sense to target?)

We give up a bit: intend to build around a de Bruijn
representation. Argue that for proofs it doesn't matter much:
typically we deal with one or two binders at at time. Scoping is
enforced by typechecking, which guides you where to insert
shifts. It actually takes quite a bit of effort to get shifts wrong. 

Pro of de Bruijn indices and contextual types (vs names, nominal
logic): purely equational; no ``propositional'' side
conditions. Compare:

$[N/x]M = M$ if $x \not\in fv(M)$, versus:

$[0 := N]M = M$ if $M = [\uparrow]M'$ for some $M'$.

This fits better into dependent type theory.

HOAS/contextual types are ``syntax'' on top of de Bruijn indices.

cite structural logical relations: requires auxiliary logic, deviates
somewhat from the on-paper techniques? \citep{Schurmann08}

cite POPLMark \cite{POPLMark}

cite Altenkirch complaining about de Bruijn indices

CoqMT approach to implementation?

In defense of intensional type theory: *smaller* checkable
witnesses. (both beta and OL substitution equations)

Spells out equality testing -- algorithm, not heuristic.

\subsection{Conversion in type theory}
A central issue in the design of a dependent type theory is
conversion: when are two types deemed to be equal? In
intensional type theories, conversion is decidable, but somewhat
weak, typically including only $\beta$ laws and perhaps some $\eta$
laws. There has been substantial work on the design and verification
of algorithms for deciding increasingly richer theories, typically
with more forms of $\eta$ laws. To take a
small selection: \cite{Coquand91,Harper05,Abel11}. Recently,
\cite{Allais13} have developed promising techniques for incorporating equations
which are neither $\beta$ nor $\eta$ laws, such as the associativity
and unit laws for list append. It remains open to establish if 
these techniques can be applied to rich dependent type theories.

\subsection{Indexed recursive types}
Recently, we have developed LF-indexed recursive types
\citep{Cave12}, as a stepping stone to support LF-indexed inductive
types. This was a first step in exploring how HOAS types can fit
into a picture with traditional recursive (or inductive..) datatypes. 

Recursive types are suitable for programming, but they do not suffice
if we are interested in proofs: need positivity. don't quite suffice
for logical relations: need universe (large eliminations) to justify,
since they aren't positive definitions/
\subsection{First class substitutions}
Our work on first-class substitutions \citep{Cave13} identifies ...
\LONGVERSION{This is precisely what is needed to support the fact that substitution
is monadic \cite{?}}


Develops decision procedure for a weaker setting: hereditiary
substitution works well for indexed types, but it does not scale well
to richer dependent types. 

\subsection{Logical relations in contextual type theory}
\citep{Cave14}
\subsection{Example}
\section{Remaining to be done}
\subsection{Computation in types}
\begin{itemize}
\item motivation
\begin{itemize}
\item richer tools (functions which compute instead of functional
relations) for more effective proofs
\item necessary to support state-of-the-art proofs involving polymorphism,
universes, ``generic programming'', dependent types, step indexing.
\end{itemize}
\item basic design sketch
\begin{itemize}
\item technique for induction principle: induct over ``all of LF'' uniformly, permitting mutual definitions, etc.
\end{itemize}
\item technical results I am aiming to achieve: decidability
  of typechecking, (strong) normalization
\item Algorithm for typechecking: \citep{Coquand91,Harper05,Abel11}
\end{itemize}

Along lines of DML, ATS: specialized for metatheory. ``New equations for neutral terms'' \cite{Allais13}

Logical step-indexed logical relations: \cite{Dreyer11}.

intensional type theory is a language of verifiable evidence (McBride's term?)
\section{Timeline}
\begin{itemize}
\item Next 6 months: working out the metatheory and examples of computation in
types, potentially for a POPL paper in July.
\item 6 months: prototype implementation and implementing examples

 - Implementing examples is key to demonstrating the value of this
 approach. I have conducted many such proofs in Agda: There are three
 main practical obstacles to carrying out such proofs 1) one needs a
 sufficient understanding of techniques for dealing with de Bruijn
 indices 2) one of course needs to understanding the proofs 3)
 applying the equational theory of simultaneous substitutions. 1 and 2
 I have tackled, and 3 is still a burden: this is what I propose to address
\item 6 months: writing thesis
\item backup/option: Some kind of ``initial algebra semantics'' for hypothetical judgments?
\item optional piece: support for (and examples of) step-indexed
  logical relations
\item (Journal version of rec types paper combined with subst. vars?)
\end{itemize}

\bibliographystyle{plainnat}
\bibliography{proposal}
\end{document}