\documentclass[usenames,dvipsnames]{beamer}
\setbeamertemplate{footline}[frame number]
\usepackage{alltt}

\usepackage{tikz}
\usetikzlibrary{arrows,automata}
\setbeamertemplate{navigation symbols}{}%remove navigation symbols


\usepackage{srcltx}
\usepackage[tikz]{bclogo}


\providecommand{\term}[1]{\mbox{\small{\textsf{#1}}}}

\newcommand{\const}[1]{\textbf{#1}}
\newcommand{\bnfas}{\mathrel{::=}}
\newcommand{\bnfalt}{\mathrel{\mid}}
\newcommand{\arrow}{\to}
\newcommand{\lam}[1]{\lambda #1. }
\usepackage{proof}
\newcommand{\entails}{\vdash}
\newcommand{\der}{\vdash}
\newcommand{\stepsto}{\longrightarrow}
\newcommand{\id}{\text{id}}
\setbeamertemplate{itemize item}{\scriptsize\raise1.25pt\hbox{\donotcoloroutermaths$\blacktriangleright$}}
\setbeamertemplate{itemize subitem}{\tiny\raise1.5pt\hbox{\donotcoloroutermaths$\bullet$}}
\setbeamertemplate{itemize subsubitem}{\tiny\raise1.5pt\hbox{\donotcoloroutermaths$-$}}

\author{Andrew Cave}
\title[{\makebox[.45\paperwidth]{Dependent Type Theory for Contextual Reasoning\hfill%
       \insertframenumber/\inserttotalframenumber}}]{Dependent Type Theory for Contextual Reasoning} 
\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Introduction}
\begin{itemize}
\item Proofs can be long and error-prone to check by hand
\pause
\item e.g. Feit Thompson theorem: proof spans 2 books, 350 pages
\pause
\item Lots of work on languages for machine-checkable proofs (Automath, Mizar, Coq, ...)
\pause \item {\color{green} Pro:} coming up with proofs can be \emph{interactive}
\begin{itemize}
\item System: ``Goal is X''
\item Human prover: ``Use lemma foo''
\item System: ``New subgoals: Y and Z''
\end{itemize}
\pause \item {\color{red} Con:} on paper we like to elide details
\begin{itemize}
\item How can we do the same for machine-checked formalizations?
\item Need to somehow equip proof checker with domain-specific procedures
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Introduction cont'd}
\begin{itemize}
\item Proofs in programming language theory: prime
candidates for formalization?
\begin{itemize}
\item Inductive reasoning is well understood
\item Lots of cases! Can be
tedious and error-prone to write \& verify by hand.
\end{itemize}
\pause
\item Burdensome part: giving a formal treatment of variable binding and
substitution.
\end{itemize}
\pause
\begin{quote}
When doing the formalization, I discovered that the core part of the
proof [...] is fairly straightforward and
only requires a good understanding of the paper version. However, in
completing the proof I observed that in certain places I had to invest
much more work than expected, e.g. proving lemmas about substitution
and weakening. -- Thorsten Altenkirch, 1993

   (formalizing normalization of System F)
\end{quote}
\pause
% \begin{itemize}
% \item 20 years later: This proof still hasn't been done in a less painful way(?!)
% \end{itemize}
\end{frame}

\begin{frame}{Thesis}
\begin{quote}Building a logical framework into dependent type
theory is possible and makes mechanization of state-of-the-art programming
language metatheory more effective.
\end{quote}
\begin{itemize}
\pause
\item More generally: Learn some lessons on how
to make mechanization of proofs outside of programming languages and
logic more practical?
\end{itemize}
\end{frame}

\begin{frame}{Background: Support for binding and substitution}
\begin{itemize}
\item Lots of approaches to support binding and substitution
\item Higher-order abstract syntax (HOAS) one of the most effective
\item The logical framework LF is well-suited for representing
programming language syntax, logics and hypothetical
judgments.
\item Less clear how to formulate induction
over HOAS representations
\item Steep price: fairly weak logics (Twelf: $\forall\exists$; Beluga: better...)
\item Abella: first order logic (weak)
\item Hybrid, nominal logic, locally nameless, etc: less support for substitution
\end{itemize}
\end{frame}

\begin{frame}{Background: Dependent type theory}
\begin{itemize}
\item Approaches to logics/languages for
machine checked proofs: Higher order logic, set theory, and dependent
type theory
\item Dependent type theory comes equipped with a direct
connection to computer programming.
\item Rich environment supports both proofs and
programs.
\item A proof in dependent type theory is an algorithm
\item Theory and implementation, hand in hand!
\item Intensional dependent type theory includes a decidable equational theory
\end{itemize}
\end{frame}


\begin{frame}[fragile]{Motivating Example: Proof by logical relations}{Simply-typed lambda calculus definition}
\[
\begin{array}{lrcl}
\mbox{Types} & A,B & \bnfas & {\const b} \bnfalt A \arrow B \\
\mbox{Terms} & M,N & \bnfas & {\const c} \bnfalt x \bnfalt \lam x M \bnfalt M\;N \\
\mbox{Values} & V & \bnfas & {\const c} \bnfalt \lam x M
\end{array}
\]
\pause
\[
\begin{array}{l}
\infer{\Gamma \vdash x : A}{\Gamma(x) = A}
\quad
\infer{\Gamma \entails \lam x M : A \arrow B}
      {\Gamma,x{:}A \der M : B}
\\[0.4em]
\infer{\Gamma \entails {\const c} : {\const b}}{}
\quad
\infer{\Gamma \entails M\; N : B}
      {\Gamma \entails M : A \arrow B & \Gamma \entails N : A}
\end{array}
\]
\pause
\[
\begin{array}{l}
\infer[\mathsf{beta}]{(\lam x M) N \stepsto [N/x]M}{}
\quad
\infer[\mathsf{app}]{M\;N \stepsto M'\;N}{M \stepsto M'}
\end{array}
\]

A term $M$ halts if there exists a value $V$ such that $M
\stepsto^* V$.
\end{frame}

\begin{frame}[fragile]{Motivating Example: Proof by logical relations}{Weak normalization}
\begin{itemize}
\item Goal: If $\vdash M : A$ then $M$ halts
\item Typical structure:
\begin{enumerate}
\item Define predicate $\mathcal{R}_A$ (``logical relation'')
% \item Show if $M' \in \mathcal{R}_A$ and $M \stepsto M'$ then $M \in \mathcal{R}_A$
\item Show if $M \in \mathcal{R}_A$ then $M$ halts
\item Show if $\vdash M : A$ then $M \in \mathcal{R}_A$
\pause

Generalize: If $\Gamma \vdash M : A$ and $\sigma \in \mathcal{R}_\Gamma$ then $[\sigma]M \in \mathcal{R}_A$
\end{enumerate}
\end{itemize}
% We prove the more general result that every term of type $A$ is \textbf{reducible} at type $A$, where reducibility is defined:
% \[
% \begin{array}{l}
% \mathcal{R}_{\const i} = \{M\; |\; M \text{ halts}\} \\
% \mathcal{R}_{A \arrow B} = \{M\; |\; M \text{ halts and } \forall N
% \in \mathcal{R}_A, (M\; N) \in \mathcal{R}_B \}
% \end{array}
% \]

% \pause
% \begin{lemma}[Backward closure]
% If $M' \in \mathcal{R}_A$ and $M \stepsto M'$ then $M \in \mathcal{R}_A$
% \end{lemma}
\end{frame}

\begin{frame}{Motivating Example: Proof by logical relations}{Definition of $\mathcal{R}$}
\[
\begin{array}{l}
\mathcal{R}_{\const b} = \{M\; |\; M \text{ halts}\} \\
\mathcal{R}_{A \arrow B} = \{M\; |\; M \text{ halts and } \forall N
\in \mathcal{R}_A, (M\; N) \in \mathcal{R}_B \}
\end{array}
\]
\end{frame}

\begin{frame}{Motivating Example: Proof by logical relations}{Main lemma}

\begin{theorem}[Fundamental theorem]
If $\Gamma \vdash M : A$ and $\sigma \in \mathcal{R}_\Gamma$ then
$[\sigma]M \in \mathcal{R}_A$.
\end{theorem}
\pause
\begin{proof}
By induction on the typing derivation. 
Case $\begin{array}{l}\infer{\Gamma \der \lam x M : A \arrow
    B}{\Gamma,x{:}A \der M : B}\end{array}$:

First, {\color{purple} $[\sigma](\lam x M) = \lam x ([\sigma,x/x]M)$} halts, since it
is a value. Suppose then that we are given $N \in \mathcal{R}_A$.

\begin{enumerate}
\item $[\sigma,N/x]M \in \mathcal{R}_B$ (by I.H. since extending
  $\sigma$ with $N$ is reducible)
\item {\color{purple} $[N/x][\sigma,x/x]M \in \mathcal{R}_B$ (property of
  substitution; $x$ assumed fresh for $\sigma$)}
\item $(\lam x ([\sigma,x/x]M))\; N \in \mathcal{R}_B$ (by closure
  under expansion)
\end{enumerate}
Hence $[\sigma](\lam x M) \in \mathcal{R}_{A \arrow B}$ (by definition)
\end{proof}
\end{frame}

\begin{frame}{Indexed recursive types}
\begin{itemize}
\item Adds LF-indexed recursive types [Cave and Pientka 2012]
\item Proof theoretic strength: richer forms of induction
\item Can express forms of predicates that LF can't e.g.
\begin{itemize}
\item certain subexpressions are \emph{closed}
\item relations between contexts
\end{itemize}
\item Not ideal: relations between contexts are typically \emph{functional} relations: why not treat them as \emph{functions}
\item \emph{Too much} strength: new ways to prove false!
\end{itemize}
\end{frame}

\begin{frame}{First class substitutions}
\begin{itemize}
\item Special built-in type of substitutions with equational theory [Cave and Pientka 2013]
\item Convenient for logical relations: need to quantify over ``closing substitutions''
\begin{theorem}[Fundamental theorem]
If $\Gamma \vdash M : A$ {\color{purple} and $\sigma \in \mathcal{R}_\Gamma$} then
$[\sigma]M \in \mathcal{R}_A$.
\end{theorem}
\item New equations to solve: $[N/x][\sigma,x/x]M = [\sigma,N/x]M$ provided $x \not\in fv(\sigma)$
\end{itemize}
\end{frame}

\begin{frame}{Logical relations in contextual type theory}
\begin{itemize}
\item Completeness of algorithmic equality for STLC
\item Proof is ``easy'': lemmas about substitutions are simple and few in number
\item Lacks check that definitions are reasonable (positivity)
\end{itemize}
\end{frame}


\begin{frame}{Proposed work: ``Computation in types''}
\begin{itemize}
\item Fit into dependent type theory
\item Supports computation in types
\item e.g. concatenation of contexts, functions from contexts to contexts instead of relations
% \item We can represent intrinsically well-typed object logics with inductive types, but it's repetitive to do define and prove properties of substitution for each object logic. Solution: Implement one, canonical forms LF, in which many others fit. (e.g. show intrinsically typed STLC?)
% \item Refinement: Build this datatype and related operations into the theory so we can support an equational theory for it.
% \item Resulting theory looks like \textbf{dependently typed} Beluga
\item Support universes (``necessary'' to justify logical relations)
% \item (predicative) polymorphism
\end{itemize}
\end{frame}

\begin{frame}[fragile]{The problem with first order encodings}
\begin{verbatim}
data exp (G : ctx) : tp -> Set where
 v : var G T -> exp G T
 app : exp G (arr T S) -> exp G T -> exp G S
 lam : exp (G , T) S -> exp G (arr T S)
\end{verbatim}
\pause
\begin{alltt}
[_] : sub G' G -> exp G T -> exp G' T
[_]' : sub G' G -> sub G D -> sub G' D
\end{alltt}
\pause
\begin{alltt}
lem1 : [ [ \(\sigma1\) ]' \(\sigma2\) ] = [ \(\sigma1\) ] \(\circ\) [ \(\sigma2\) ]
lem2 : [ \(\sigma\) , M ] \(\circ\) \(\uparrow\) = [ \(\sigma\) ]
lem3 : [ id ]' \(\sigma\) = \(\sigma\)
lem4 : [ id , N ] \(\circ\) [ \(\uparrow\) \(\sigma\), 1 ] = [ \(\sigma\) , N ]
...
\end{alltt}
This is tedious to do for each language we study!

\end{frame}

\begin{frame}{A solution?}
\begin{itemize}
\pause \item We know that LF works well to encode object languages...
\pause \item So do this *once* for LF, and embed your OL inside
\pause \item I've prototyped this in Agda
\pause \item $>$48GB of memory to typecheck an example
\pause \item And we still have to apply these lemmas manually and often compose several of them
\pause \item Solution: build LF datatype into DTT and build lemmas into conversion check
\pause \item Result: ``dependently typed Beluga''
\pause \item Analyze LF objects by the induction principle you get from considering an inductive type representing LF
\pause \item provides ``simple'' approach to semantics, termination (via eliminator for LF datatype)?
\end{itemize}
\end{frame}

\begin{frame}{The metric for success}
\begin{itemize}
\item Algorithm for typechecking (decidability, soundness, completeness)
\item Consequences: normalization, consistency
\item Prototype implementation
\item Formalize non-trivial proofs, e.g.
\begin{itemize}
\item C. Coquand's normalization proof for MLTT with a universe
\item logical relation for contextual equivalence (parametricity)
\item soundness and completeness of NbE
\item normalization for System F?
\end{itemize}
\end{itemize}
\end{frame}

\end{document}
